常用模糊查询的查询条件为:{start=0,q=platenumber:浙C* AND datenumber:[1475942400000 TO 1476028799000],sort=datenumber desc,shards.tolerant=false,fl=id,direction,firstpicpath,directionid,datenumber,platetype,lanename,secondpicpath,platenumber,passportid,passportname,speed,carscolor,creator,platerecttop,platerectleft,platerectwidth,platerectheight,rows=1000}

注:下面查询条件中all:( 02 C)是我们弄的一个copyField,里面的02代表小型汽车,C代表车身颜色为黄色

带copyField的查询条件为:{start=0,q=all:( 02 C) AND platenumber:浙C* AND datenumber:[1475942400000 TO 1476028799000],sort=datenumber desc,shards.tolerant=false,fl=id,direction,firstpicpath,directionid,datenumber,platetype,lanename,secondpicpath,platenumber,passportid,passportname,speed,carscolor,creator,platerecttop,platerectleft,platerectwidth,platerectheight,rows=1000}

{start=0,q=all:( 02 C) AND platenumber:浙* AND datenumber:[1475942400000 TO 1476028799000],sort=datenumber desc,shards.tolerant=false,fl=id,direction,firstpicpath,directionid,datenumber,platetype,lanename,secondpicpath,platenumber,passportid,passportname,speed,carscolor,creator,platerecttop,platerectleft,platerectwidth,platerectheight,rows=1000}



精确查询的查询条件为:{start=0,q=platenumber:浙C123456 AND datenumber:[1475942400000 TO 1476028799000],sort=datenumber desc,shards.tolerant=false,fl=id,direction,firstpicpath,directionid,datenumber,platetype,lanename,secondpicpath,platenumber,passportid,passportname,speed,carscolor,creator,platerecttop,platerectleft,platerectwidth,platerectheight,rows=1000}

带copyField的查询条件为:{start=0,q=all:( 02 C) AND platenumber:浙C123456 AND datenumber:[1475942400000 TO 1476028799000],sort=datenumber desc,shards.tolerant=false,fl=id,direction,firstpicpath,directionid,datenumber,platetype,lanename,secondpicpath,platenumber,passportid,passportname,speed,carscolor,creator,platerecttop,platerectleft,platerectwidth,platerectheight,rows=1000}

现在的问题如下:
1.我们系统每天的过车数据平均为两千万左右,在查询过程中通常需要按照过车时间排序,通过这种方式查询时速度很慢,在需要查询出一段时间内的总数量时会更慢,按照上面的条件查询精确查询大约在6s-8s左右,模糊查询在8s-12s左右;

2.我们的片区是按照月来划分的,在跨片区的时候利用solr的聚合查询如group facet和facet.pivot进行时对跨片区的情况无法处理,因为我们需要的结果通常是一个时间段内通过一次聚合得到的,这样就只能利用hadoop和spark来进行分析了,solr自身的新特性就没能运用上.












